有用链接

工具
https://tool.lu/encdec/
http://tool.oschina.net/codeformat/js
内容不错：
https://www.jianshu.com/p/1476a181fc57
https://cuiqingcai.com/6182.html
https://cuiqingcai.com/4048.html的
##使用REDIS_URL链接Redis数据库, deconde_responses=True这个参数必须要，数据会变成byte形式 完全没法用
reds = redis.Redis.from_url(REDIS_URL, db=2, decode_responses=True)
间书
https://www.jianshu.com/p/777b7712249c
https://www.jianshu.com/p/de16a1093c7e

------------------------
cookiedict={}
requests.utils.add_dict_to_cookiejar(ssrequest.cookies,cookiedict)
cookiejar是个对象,将对象转为字典
cookiedict={}
for item in response.cookies:
	cookiedict[item.name]=item.value

#-------------------------------
npm install crypto-js
要用 AES 算法加密，首先我们要引入 crypto-js ，crypto-js 是一个纯 javascript 写的加密算法类库 ，
可以非常方便地在 javascript 进行 MD5、SHA1、SHA2、SHA3、RIPEMD-160 哈希散列，
进行 AES、DES、Rabbit、RC4、Triple DES 加解密


all(iterable) not all() 
all 列表， 元组元素都不为空或0
 all([])  >>>True      # 空列表
 all(())  >>>True      # 空元组

label标签一般用于form表单内

爬虫项目
https://yq.aliyun.com/articles/644882?spm=a2c4e.11155472.0.0.55af7c40a9qtM8

进阶
http://k.sina.com.cn/article_6436010038_17f9db8360010057d3.html
cookie看
scrapy中得到cookie
cookies = response.cookies.get_dict()
https://www.jianshu.com/p/7a1b8c144d83
https://doc.scrapy.org/en/1.3/topics/downloader-middleware.html#cookies-mw
#-------------------------------
scrapy的安装
https://blog.csdn.net/android_ztz/article/details/79243521
https://www.jianshu.com/p/7a1b8c144d83
https://doc.scrapy.org/en/1.3/topics/downloader-middleware.html#cookies-mw
http://k.sina.com.cn/article_6436010038_17f9db8360010057d3.html
cookie看
scrapy中得到cookie
cookies = response.cookies.get_dict()

from scrapy.http.cookies import CookieJar
cookiejar = CookieJar()
cookiejar.extract_cookies(response, response.request)

# 有些情况可能在发起登录之前会有一些请求,会陆续的产生一些cookie,
可以在第一次请求的时候将cookiejar写入到request的meta中进行传递

scrapy.Request(url, callback=self.xxx, meta={'cookiejar': cookiejar})
# 之后每次需要传递这个cookiejar对象可以从response.meta中拿到
scrapy.Request(url, callback=self.xxx, meta={'cookiejar': response.meta['cookiejar']})
yield Request(url,callback=self.parse, cookies=self.cookie,headers=self.headers, meta=self.meta)
保持上一次的cookie
https://doc.scrapy.org/en/latest/topics/request-response.html
yield Request(url,callback=self.parse,meta={'dont_merge_cookies': True})

scrapy发起request请求并提交参数(默认请求方式是：POST)
yield scrapy.FormRequest(url,callback=self.parse,formdata={},method="GET",errback=self.errparse,meta={})
#scrapy在parse方法后
from scrapy shell import inspect_response
inspect_response(response,self)

工具urllib encode转换
https://www.cnblogs.com/caicaihong/p/5687522.html
url.parse.unquote()



import redis
pool=redis.ConnectionPool(host='',port=6379,db=0,password=''，decode_responses=True)
r=redis.StrictRedis(connection_pool=pool)
Redis 发布订阅
https://blog.csdn.net/selina361/article/details/79708501?utm_source=blogxgwz8
import redis
pool=redis.ConnectionPool(host='',port=6379,db=0,password=''，decode_responses=True)
r=redis.StrictRedis(connection_pool=pool)

#new_
崔庆才的github
https://github.com/Python3WebSpider/ProxyPool/tree/master/proxypool
字符串转换成字典： https://www.cnblogs.com/OnlyDreams/p/7850920.html
python时间转换：  https://www.linuxidc.com/Linux/2018-12/155919.htm

https://opencv.org/releases.html（发布）
https://www.cnblogs.com/Undo-self-blog/p/8423851.html
linux社区python和opencv
https://www.linuxidc.com/topicnews.aspx?tid=17
https://www.linuxidc.com/Linux/2015-08/121400.htm

夜神模拟器
https://blog.csdn.net/hihell/article/details/86065636


